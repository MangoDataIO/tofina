{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pytorch_forecasting/data/samplers.py:86: UserWarning: Less than 32 samples available for 5486 prediction times. Use batch size smaller than 32. First 10 prediction times with small batch sizes: [31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/anaconda3/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/opt/anaconda3/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/50 [00:00<?, ?it/s]                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 50/50 [00:20<00:00,  2.47it/s, v_num=3, train_loss_step=4.680, val_loss=4.380, train_loss_epoch=4.700]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 50/50 [00:20<00:00,  2.46it/s, v_num=3, train_loss_step=4.680, val_loss=4.380, train_loss_epoch=4.700]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/opt/anaconda3/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/anaconda3/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "<ipython-input-2-00b7ff96465b>:46: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "100it [00:00, 576.13it/s]\n",
      "<ipython-input-2-00b7ff96465b>:46: DtypeWarning: Columns (2,3,4,5,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_path)\n",
      "100it [00:00, 762.38it/s]\n",
      "100%|██████████| 5000/5000 [00:45<00:00, 110.09it/s]\n",
      "100%|██████████| 1/1 [00:45<00:00, 45.48s/it]\n"
     ]
    }
   ],
   "source": [
    "from tofina.components.backtest import Backtester\n",
    "import tofina.components.instrument as instrument\n",
    "from tofina.extern.pytorch_forecasting import forecastDecoratorDeepAR\n",
    "from tofina.extern.yfinance import loadHistoricalStockData\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "AAPL = loadHistoricalStockData(\"AAPL\", start=\"2001-01-01\", end=\"2024-02-14\")\n",
    "NVDA = loadHistoricalStockData(\"NVDA\", start=\"2001-01-01\", end=\"2024-02-14\")\n",
    "\n",
    "start_date = dt.datetime(2023, 1, 1)\n",
    "#end_date = dt.datetime(2023, 1, 14)\n",
    "end_date = dt.datetime(2023, 1, 4)\n",
    "split_date = start_date - dt.timedelta(days=1)\n",
    "timestamps = AAPL.index[\n",
    "    np.logical_and(AAPL.index >= start_date, AAPL.index < end_date)\n",
    "]\n",
    "horizon = 20\n",
    "simulations = 1000\n",
    "forecaster = forecastDecoratorDeepAR(\n",
    "    {\"AAPL\":AAPL, \"NVDA\":NVDA}, split_date, \"./DeapAR_Training\", horizon, simulations,max_epochs=1\n",
    ")\n",
    "backtester = Backtester(timestamps=timestamps)\n",
    "backtester.stockDataFromDataFrame(AAPL, \"AAPL\")\n",
    "backtester.stockDataFromDataFrame(NVDA, \"NVDA\")\n",
    "backtester.registerForecaster(forecaster, [\"AAPL\", \"NVDA\"])\n",
    "backtester.addDeposit(interestRate=0.03/252)\n",
    "backtester.addIntstrumentToPortfolio(\"AAPL\", \"AAPL_Stock\", \n",
    "            instrument.NonDerivativePayout\n",
    "        )\n",
    "backtester.addIntstrumentToPortfolio(\"NVDA\", \"NVDA_Stock\", \n",
    "            instrument.NonDerivativePayout\n",
    "        )\n",
    "backtester.addIntstrumentToPortfolio(\"AAPL\", \"AAPL_Stock_Short\", \n",
    "            instrument.NonDerivativePayoutShort\n",
    "        )\n",
    "backtester.addIntstrumentToPortfolio(\"NVDA\", \"NVDA_Stock_Short\", \n",
    "            instrument.NonDerivativePayoutShort\n",
    "        )\n",
    "\n",
    "def register_option(df_path, ticker):\n",
    "    df = pd.read_csv(df_path)\n",
    "    df[\"Date\"] = df[\"Date\"].apply(lambda x: x.replace(\" \", \"\"))\n",
    "    df[\"Expiry Date\"] = df[\"Expiry Date\"].apply(lambda x: x.replace(\" \", \"\"))\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    df[\"Expiry Date\"] = pd.to_datetime(df[\"Expiry Date\"])\n",
    "    df = df[df[\"Date\"] >= start_date]\n",
    "    df = df[df[\"Date\"] < end_date]\n",
    "    backtester.parseOptionData(df, ticker, sampleOption=100)\n",
    "\n",
    "register_option(\"/Users/andriylevitskyy/Desktop/tofina/tests/data/options/AAPL.csv\", \"AAPL\")\n",
    "register_option(\"/Users/andriylevitskyy/Desktop/tofina/tests/data/options/NVDA.csv\", \"NVDA\")\n",
    "\n",
    "dir_path = Path(\"./results/DeepAR_Options\")\n",
    "if dir_path.exists():\n",
    "    shutil.rmtree(dir_path)\n",
    "dir_path.mkdir(parents=True, exist_ok=False)\n",
    "backtester.optimizeStrategy(dir_path, RiskAversion=0.9, stop=False, iterations = 5000)\n",
    "backtesterCopy = deepcopy(backtester)\n",
    "results = backtester.evaluateStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-03 00:00:00 -0.97748969898669 11156.4921875\n"
     ]
    }
   ],
   "source": [
    "for ts in timestamps:\n",
    "    print(ts, float(results[ts][\"real\"].sum(axis=1)), float(results[ts][\"simulation\"].sum(axis=1).mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps =  list(backtester.pointInTimePortfolio.keys())\n",
    "testPortfolio = backtester.pointInTimePortfolio[timestamps[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NVDA_Put_113.0_4_NVDA</th>\n",
       "      <td>0.987076</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL_Put_114.0_9_AAPL</th>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA_Put_197.5_19_NVDA</th>\n",
       "      <td>0.000260</td>\n",
       "      <td>56.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA_Call_134.0_9_NVDA</th>\n",
       "      <td>0.000259</td>\n",
       "      <td>11.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL_Call_136.0_19_AAPL</th>\n",
       "      <td>0.000259</td>\n",
       "      <td>1.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL_Call_146.0_14_AAPL</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA_Call_197.5_19_NVDA</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA_Call_205.0_4_NVDA</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA_NVDA_Stock_NVDA</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>143.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA_Put_167.5_19_NVDA</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>25.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           weight       price\n",
       "NVDA_Put_113.0_4_NVDA    0.987076    0.010000\n",
       "AAPL_Put_114.0_9_AAPL    0.000267    0.660000\n",
       "NVDA_Put_197.5_19_NVDA   0.000260   56.500000\n",
       "NVDA_Call_134.0_9_NVDA   0.000259   11.950000\n",
       "AAPL_Call_136.0_19_AAPL  0.000259    1.430000\n",
       "...                           ...         ...\n",
       "AAPL_Call_146.0_14_AAPL  0.000003    0.150000\n",
       "NVDA_Call_197.5_19_NVDA  0.000003    0.150000\n",
       "NVDA_Call_205.0_4_NVDA   0.000003    0.010000\n",
       "NVDA_NVDA_Stock_NVDA     0.000002  143.149994\n",
       "NVDA_Put_167.5_19_NVDA   0.000001   25.600000\n",
       "\n",
       "[137 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = backtester.pointInTimePortfolio[timestamps[0]].strategy.normalizedWeights\n",
    "instruments = backtester.pointInTimePortfolio[timestamps[0]].strategy.instruments.keys()\n",
    "prices = []\n",
    "for i in instruments:\n",
    "    prices.append(backtester.pointInTimePortfolio[timestamps[0]].strategy.instruments[i].price)\n",
    "weightsDict = {}\n",
    "for w,i,p in zip(weights,instruments, prices):\n",
    "    weightsDict[i] = {\"weight\":float(w), \"price\":float(p)}\n",
    "pd.DataFrame(weightsDict).T.sort_values(by=\"weight\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
